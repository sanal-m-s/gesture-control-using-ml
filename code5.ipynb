{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEe/o/g1cx511/nmKVrjm+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanal-m-s/gesture-control-using-ml/blob/main/code5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1xFb7Bsego1"
      },
      "outputs": [],
      "source": [
        "from function import *\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import model_from_json\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.callbacks import TensorBoard\n",
        "json_file = open(\"model.json\", \"r\")\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(model_json)\n",
        "model.load_weights(\"model.h5\")\n",
        "\n",
        "colors = []\n",
        "for i in range(0,20):\n",
        "    colors.append((245,117,16))\n",
        "print(len(colors))\n",
        "def prob_viz(res, actions, input_frame, colors,threshold):\n",
        "    output_frame = input_frame.copy()\n",
        "    for num, prob in enumerate(res):\n",
        "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
        "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "    return output_frame\n",
        "\n",
        "\n",
        "# 1. New detection variables\n",
        "sequence = []\n",
        "sentence = []\n",
        "accuracy=[]\n",
        "predictions = []\n",
        "threshold = 0.8\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# cap = cv2.VideoCapture(\"https://192.168.43.41:8080/video\")\n",
        "# Set mediapipe model\n",
        "with mp_hands.Hands(\n",
        "    model_complexity=0,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as hands:\n",
        "    while cap.isOpened():\n",
        "\n",
        "        # Read feed\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Make detections\n",
        "        cropframe=frame[40:400,0:300]\n",
        "        # print(frame.shape)\n",
        "        frame=cv2.rectangle(frame,(0,40),(300,400),255,2)\n",
        "        # frame=cv2.putText(frame,\"Active Region\",(75,25),cv2.FONT_HERSHEY_COMPLEX_SMALL,2,255,2)\n",
        "        image, results = mediapipe_detection(cropframe, hands)\n",
        "        # print(results)\n",
        "\n",
        "        # Draw landmarks\n",
        "        # draw_styled_landmarks(image, results)\n",
        "        # 2. Prediction logic\n",
        "        keypoints = extract_keypoints(results)\n",
        "        sequence.append(keypoints)\n",
        "        sequence = sequence[-30:]\n",
        "\n",
        "        try:\n",
        "            if len(sequence) == 30:\n",
        "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "                print(actions[np.argmax(res)])\n",
        "                predictions.append(np.argmax(res))\n",
        "\n",
        "\n",
        "            #3. Viz logic\n",
        "                if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
        "                    if res[np.argmax(res)] > threshold:\n",
        "                        if len(sentence) > 0:\n",
        "                            if actions[np.argmax(res)] != sentence[-1]:\n",
        "                                sentence.append(actions[np.argmax(res)])\n",
        "                                accuracy.append(str(res[np.argmax(res)]*100))\n",
        "                        else:\n",
        "                            sentence.append(actions[np.argmax(res)])\n",
        "                            accuracy.append(str(res[np.argmax(res)]*100))\n",
        "\n",
        "                if len(sentence) > 1:\n",
        "                    sentence = sentence[-1:]\n",
        "                    accuracy=accuracy[-1:]\n",
        "\n",
        "                # Viz probabilities\n",
        "                # frame = prob_viz(res, actions, frame, colors,threshold)\n",
        "        except Exception as e:\n",
        "            # print(e)\n",
        "            pass\n",
        "\n",
        "        cv2.rectangle(frame, (0,0), (300, 40), (245, 117, 16), -1)\n",
        "        cv2.putText(frame,\"Output: -\"+' '.join(sentence)+''.join(accuracy), (3,30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Show to screen\n",
        "        cv2.imshow('OpenCV Feed', frame)\n",
        "\n",
        "        # Break gracefully\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2b8bw0nNhZtl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}